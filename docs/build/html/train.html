<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training examples of AI-centered model &mdash; GWAI  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples of evaluation method" href="evaluation.html" />
    <link rel="prev" title="Examples of space-based gravitational wave signal generation" href="waveform.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            GWAI
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about_gwai.html">About GWAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="waveform.html">Examples of space-based gravitational wave signal generation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Training examples of AI-centered model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#signal-classification">Signal Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-denoising">Data Denoising</a></li>
<li class="toctree-l3"><a class="reference internal" href="#signal-detection">Signal Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="evaluation.html">Examples of evaluation method</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">src</a></li>
<li class="toctree-l1"><a class="reference internal" href="citations.html">Citations</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GWAI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Training examples of AI-centered model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/train.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="training-examples-of-ai-centered-model">
<h1>Training examples of AI-centered model<a class="headerlink" href="#training-examples-of-ai-centered-model" title="Link to this heading"></a></h1>
<table class="autosummary longtable docutils align-default">
<tbody>
</tbody>
</table>
<section id="signal-classification">
<h2>Signal Classification<a class="headerlink" href="#signal-classification" title="Link to this heading"></a></h2>
<p>Firstly, activating <code class="docutils literal notranslate"><span class="pre">waveform</span></code> environment.
Then, by running <a class="reference external" href="https://github.com/AI-HPC-Research-Team/GWAI/tree/main/demos/train_classify.py">train_classify.py</a> script, your own signal classification model can be trained.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>waveform
<span class="linenos">2</span><span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>/workspace/GWAI/demos
<span class="linenos">3</span><span class="gp">$ </span>python<span class="w"> </span>train_classify.py
</pre></div>
</div>
<p>You can modify <a class="reference external" href="https://github.com/AI-HPC-Research-Team/GWAI/tree/main/configs/classify.yaml">classify.yaml</a> to define your own training dataset as well as model configurations. For example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="nt">dataset</span><span class="p">:</span>
<span class="linenos"> 2</span><span class="nt">save_path</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;../datasets/classify/&quot;</span>
<span class="linenos"> 3</span><span class="nt">fn</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">emri_asd_test.hdf5</span>
<span class="linenos"> 4</span><span class="nt">dataloader</span><span class="p">:</span>
<span class="linenos"> 5</span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="linenos"> 6</span><span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="linenos"> 7</span>
<span class="linenos"> 8</span><span class="nt">training</span><span class="p">:</span>
<span class="linenos"> 9</span><span class="nt">test_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos">10</span><span class="nt">checkpoint_dir</span><span class="p">:</span>
<span class="linenos">11</span><span class="nt">gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="linenos">12</span><span class="nt">n_epoch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50</span>
<span class="linenos">13</span><span class="c1"># loss_fn: &quot;bce_with_logits&quot;</span>
<span class="linenos">14</span><span class="nt">loss_fn</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;cross_entropy&quot;</span>
<span class="linenos">15</span><span class="nt">optimizer_type</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;adam&quot;</span>
<span class="linenos">16</span><span class="nt">optimizer_kwargs</span><span class="p">:</span>
<span class="linenos">17</span><span class="w">    </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5e-5</span>
<span class="linenos">18</span><span class="w">    </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="linenos">19</span><span class="nt">scheduler_type</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;plateau&quot;</span>
<span class="linenos">20</span><span class="nt">scheduler_kwargs</span><span class="p">:</span>
<span class="linenos">21</span><span class="w">    </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;min&quot;</span>
<span class="linenos">22</span><span class="w">    </span><span class="nt">factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="linenos">23</span><span class="w">    </span><span class="nt">patience</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="linenos">24</span><span class="w">    </span><span class="nt">threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-4</span>
<span class="linenos">25</span><span class="nt">result_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;./results//${now:%Y-%m-%d}/${now:%H-%M-%S}&quot;</span>
<span class="linenos">26</span><span class="nt">result_fn</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;inf_result.npy&quot;</span>
<span class="linenos">27</span><span class="nt">use_wandb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos">28</span>
<span class="linenos">29</span><span class="nt">net</span><span class="p">:</span>
<span class="linenos">30</span><span class="nt">input_channels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos">31</span><span class="nt">n_classes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos">32</span><span class="nt">n_hidden</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="linenos">33</span><span class="nt">n_levels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="linenos">34</span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="linenos">35</span><span class="nt">num_classes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos">36</span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
</pre></div>
</div>
<p>The output log can be seen as follows.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w">  </span><span class="o">[</span><span class="m">2024</span>-02-04<span class="w"> </span><span class="m">10</span>:25:46,915<span class="o">][</span>nn.dataloader<span class="o">][</span>INFO<span class="o">]</span><span class="w"> </span>-<span class="w"> </span>Loading<span class="w"> </span>data<span class="w"> </span>from<span class="w"> </span>../datasets/detection/emri_asd_test.hdf5
<span class="linenos"> 2</span><span class="w">  </span>Using<span class="w"> </span>Adam<span class="w"> </span>optimizer,<span class="w"> </span><span class="nv">lr</span><span class="o">=</span>5e-05,<span class="w"> </span><span class="nv">weight_decay</span><span class="o">=</span><span class="m">0</span>.001
<span class="linenos"> 3</span><span class="w">  </span>Total<span class="w"> </span>parameters:<span class="w"> </span><span class="m">940</span>.42K
<span class="linenos"> 4</span><span class="w">  </span>Trainable<span class="w"> </span>parameters:<span class="w"> </span><span class="m">940</span>.42K
<span class="linenos"> 5</span><span class="w">  </span>Non-trainable<span class="w"> </span>parameters:<span class="w"> </span><span class="m">0</span>
<span class="linenos"> 6</span><span class="w">  </span>Epoch<span class="w"> </span><span class="m">1</span>:<span class="w"> </span><span class="m">100</span>%<span class="p">|</span>█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">200</span>/200<span class="w"> </span><span class="o">[</span><span class="m">00</span>:01&lt;<span class="m">00</span>:00,<span class="w"> </span><span class="m">138</span>.53it/s,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="m">6</span>.94e-01,<span class="w"> </span><span class="nv">acc</span><span class="o">=</span><span class="m">0</span>.49<span class="o">]</span><span class="w">                                                                                                                                                                                                 </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>/200<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;?,<span class="w"> </span>?it/s<span class="o">]</span>Time:<span class="w"> </span><span class="m">0</span>.010484933853149414
<span class="linenos"> 7</span><span class="w">  </span><span class="m">100</span>%<span class="p">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">200</span>/200<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;<span class="m">00</span>:00,<span class="w"> </span><span class="m">223</span>.66it/s,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="m">6</span>.91e-01,<span class="w"> </span><span class="nv">acc</span><span class="o">=</span><span class="m">0</span>.5050<span class="o">]</span>
<span class="linenos"> 8</span><span class="w">  </span><span class="o">[</span><span class="m">2024</span>-02-04<span class="w"> </span><span class="m">10</span>:25:54,895<span class="o">][</span>nn.trainer<span class="o">][</span>INFO<span class="o">]</span><span class="w"> </span>-<span class="w"> </span>EPOCH<span class="w"> </span><span class="m">1</span><span class="w">   </span>:<span class="w"> </span><span class="nv">lr</span><span class="o">=</span><span class="m">5</span>.00e-05,<span class="w">   </span><span class="nv">train_loss</span><span class="o">=</span><span class="m">6</span>.94e-01,<span class="w">    </span><span class="nv">train_acc</span><span class="o">=</span><span class="m">0</span>.4900,<span class="w">       </span><span class="nv">val_loss</span><span class="o">=</span><span class="m">6</span>.91e-01<span class="w">       </span><span class="nv">valid_acc</span><span class="o">=</span><span class="m">0</span>.5050
<span class="linenos"> 9</span><span class="w">  </span>Epoch<span class="w"> </span><span class="m">2</span>:<span class="w"> </span><span class="m">100</span>%<span class="p">|</span>█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">200</span>/200<span class="w"> </span><span class="o">[</span><span class="m">00</span>:01&lt;<span class="m">00</span>:00,<span class="w"> </span><span class="m">156</span>.30it/s,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="m">6</span>.91e-01,<span class="w"> </span><span class="nv">acc</span><span class="o">=</span><span class="m">0</span>.50<span class="o">]</span>
<span class="linenos">10</span><span class="w">  </span><span class="m">0</span>%<span class="p">|</span><span class="w">                                                                                                                                                                                                  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>/200<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;?,<span class="w"> </span>?it/s<span class="o">]</span>Time:<span class="w"> </span><span class="m">0</span>.010904073715209961
</pre></div>
</div>
</section>
<section id="data-denoising">
<h2>Data Denoising<a class="headerlink" href="#data-denoising" title="Link to this heading"></a></h2>
<p>Firstly, downloading demo dataset (<code class="docutils literal notranslate"><span class="pre">train_data,</span> <span class="pre">valid_data,</span> <span class="pre">test_data</span></code>) from <a class="reference external" href="https://github.com/AI-HPC-Research-Team/LIGO_noise_suppression">this repository</a>.
and put it under <a class="reference external" href="https://github.com/AI-HPC-Research-Team/GWAI/tree/main/datasets/denoise">datasets/denoise</a> folder.
By running <a class="reference external" href="https://github.com/AI-HPC-Research-Team/GWAI/tree/main/demo/denoise_demo.sh">denoise_demo.sh</a> script, your own denoising model can be trained.</p>
<p>You can modify configurations in <a class="reference external" href="https://github.com/AI-HPC-Research-Team/GWAI/tree/main/demo/denoise_demo.sh">denoise_demo.sh</a> to build your own model with different model size.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>base
<span class="linenos">2</span><span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>/workspace/GWAI/demos
<span class="linenos">3</span><span class="gp">$ </span>bash<span class="w"> </span>denoise_demo.sh
</pre></div>
</div>
<p>The training parameters can be modified in <cite>denoise_demo.sh</cite>, for example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="ch">#!/bin/bash</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="nv">GPUS_PER_NODE</span><span class="o">=</span><span class="m">2</span>
<span class="linenos"> 4</span><span class="nv">MASTER_ADDR</span><span class="o">=</span>localhost
<span class="linenos"> 5</span><span class="nv">MASTER_PORT</span><span class="o">=</span><span class="m">6066</span>
<span class="linenos"> 6</span><span class="nv">NNODES</span><span class="o">=</span><span class="m">1</span>
<span class="linenos"> 7</span><span class="nv">NODE_RANK</span><span class="o">=</span><span class="m">0</span>
<span class="linenos"> 8</span><span class="nv">WORLD_SIZE</span><span class="o">=</span><span class="k">$((</span><span class="nv">$GPUS_PER_NODE</span><span class="o">*</span><span class="nv">$NNODES</span><span class="k">))</span>
<span class="linenos"> 9</span><span class="nv">DATA_PATH</span><span class="o">=</span>../dataset/denoise
<span class="linenos">10</span>
<span class="linenos">11</span><span class="nv">DETS</span><span class="o">=</span>H1
<span class="linenos">12</span><span class="nv">CHECKPOINT_PATH</span><span class="o">=</span>demo
<span class="linenos">13</span>
<span class="linenos">14</span><span class="nv">DISTRIBUTED_ARGS</span><span class="o">=</span><span class="s2">&quot;--nproc_per_node </span><span class="nv">$GPUS_PER_NODE</span><span class="s2"> --nnodes </span><span class="nv">$NNODES</span><span class="s2"> --node_rank </span><span class="nv">$NODE_RANK</span><span class="s2"> --master_addr </span><span class="nv">$MASTER_ADDR</span><span class="s2"> --master_port </span><span class="nv">$MASTER_PORT</span><span class="s2">&quot;</span>
<span class="linenos">15</span>
<span class="linenos">16</span><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">6</span>,7
<span class="linenos">17</span>python<span class="w"> </span>-m<span class="w"> </span>torch.distributed.launch<span class="w"> </span><span class="nv">$DISTRIBUTED_ARGS</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">18</span><span class="w">    </span>pretrain_gw.py<span class="w"> </span><span class="se">\</span>
<span class="linenos">19</span><span class="w">    </span>--tensor-model-parallel-size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">20</span><span class="w">    </span>--pipeline-model-parallel-size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">21</span><span class="w">    </span>--num-layers<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">22</span><span class="w">    </span>--hidden-size<span class="w"> </span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">23</span><span class="w">    </span>--num-attention-heads<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">24</span><span class="w">    </span>--micro-batch-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">25</span><span class="w">    </span>--segment-length<span class="w"> </span><span class="m">256</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">26</span><span class="w">    </span>--dets<span class="w"> </span><span class="nv">$DETS</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">27</span><span class="w">    </span>--seq-length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">28</span><span class="w">    </span>--max-position-embeddings<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">29</span><span class="w">    </span>--train-iters<span class="w"> </span><span class="m">30000</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">30</span><span class="w">    </span>--save<span class="w"> </span><span class="nv">$CHECKPOINT_PATH</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">31</span><span class="w">    </span>--load<span class="w"> </span><span class="nv">$CHECKPOINT_PATH</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">32</span><span class="w">    </span>--data-path<span class="w"> </span><span class="nv">$DATA_PATH</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">33</span><span class="w">    </span>--data-impl<span class="w"> </span>mmap<span class="w"> </span><span class="se">\</span>
<span class="linenos">34</span><span class="w">    </span>--split<span class="w"> </span><span class="m">949</span>,50,1<span class="w"> </span><span class="se">\</span>
<span class="linenos">35</span><span class="w">    </span>--distributed-backend<span class="w"> </span>nccl<span class="w"> </span><span class="se">\</span>
<span class="linenos">36</span><span class="w">    </span>--lr<span class="w"> </span><span class="m">0</span>.0001<span class="w"> </span><span class="se">\</span>
<span class="linenos">37</span><span class="w">    </span>--lr-decay-style<span class="w"> </span>linear<span class="w"> </span><span class="se">\</span>
<span class="linenos">38</span><span class="w">    </span>--min-lr<span class="w"> </span><span class="m">1</span>.0e-5<span class="w"> </span><span class="se">\</span>
<span class="linenos">39</span><span class="w">    </span>--lr-decay-iters<span class="w"> </span><span class="m">9900</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">40</span><span class="w">    </span>--weight-decay<span class="w"> </span>1e-2<span class="w"> </span><span class="se">\</span>
<span class="linenos">41</span><span class="w">    </span>--clip-grad<span class="w"> </span><span class="m">1</span>.0<span class="w"> </span><span class="se">\</span>
<span class="linenos">42</span><span class="w">    </span>--lr-warmup-fraction<span class="w"> </span>.002<span class="w"> </span><span class="se">\</span>
<span class="linenos">43</span><span class="w">    </span>--log-interval<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">44</span><span class="w">    </span>--save-interval<span class="w"> </span><span class="m">10000</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">45</span><span class="w">    </span>--eval-interval<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="linenos">46</span><span class="w">    </span>--dataloader-type<span class="w"> </span>cyclic<span class="w"> </span><span class="se">\</span>
<span class="linenos">47</span><span class="w">    </span>--fp16<span class="w"> </span><span class="se">\</span>
<span class="linenos">48</span><span class="w">    </span>--no-binary-head
</pre></div>
</div>
<p>The output log can be seen as follows.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w">  </span>using<span class="w"> </span>world<span class="w"> </span>size:<span class="w"> </span><span class="m">2</span>,<span class="w"> </span>data-parallel-size:<span class="w"> </span><span class="m">2</span>,<span class="w"> </span>tensor-model-parallel<span class="w"> </span>size:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>pipeline-model-parallel<span class="w"> </span>size:<span class="w"> </span><span class="m">1</span>
<span class="linenos"> 2</span><span class="w">  </span>setting<span class="w"> </span>global<span class="w"> </span>batch<span class="w"> </span>size<span class="w"> </span>to<span class="w"> </span><span class="m">16</span>
<span class="linenos"> 3</span><span class="w">  </span>using<span class="w"> </span>torch.float16<span class="w"> </span><span class="k">for</span><span class="w"> </span>parameters<span class="w"> </span>...
<span class="linenos"> 4</span><span class="w">  </span>------------------------<span class="w"> </span>arguments<span class="w"> </span>------------------------
<span class="linenos"> 5</span><span class="w">  </span>accumulate_allreduce_grads_in_fp32<span class="w"> </span>..............<span class="w"> </span>False
<span class="linenos"> 6</span><span class="w">  </span>adam_beta1<span class="w"> </span>......................................<span class="w"> </span><span class="m">0</span>.9
<span class="linenos"> 7</span><span class="w">  </span>xxxxxxx
<span class="linenos"> 8</span><span class="w">  </span>--------------------<span class="w"> </span>end<span class="w"> </span>of<span class="w"> </span>arguments<span class="w"> </span>---------------------
<span class="linenos"> 9</span><span class="w">  </span>setting<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>micro-batches<span class="w"> </span>to<span class="w"> </span>constant<span class="w"> </span><span class="m">1</span>
<span class="linenos">10</span><span class="w">  </span>&gt;<span class="w"> </span>initializing<span class="w"> </span>torch<span class="w"> </span>distributed<span class="w"> </span>...
<span class="linenos">11</span><span class="w">  </span>&gt;<span class="w"> </span>initializing<span class="w"> </span>tensor<span class="w"> </span>model<span class="w"> </span>parallel<span class="w"> </span>with<span class="w"> </span>size<span class="w"> </span><span class="m">1</span>
<span class="linenos">12</span><span class="w">  </span>&gt;<span class="w"> </span>initializing<span class="w"> </span>pipeline<span class="w"> </span>model<span class="w"> </span>parallel<span class="w"> </span>with<span class="w"> </span>size<span class="w"> </span><span class="m">1</span>
<span class="linenos">13</span><span class="w">  </span>&gt;<span class="w"> </span>setting<span class="w"> </span>random<span class="w"> </span>seeds<span class="w"> </span>to<span class="w"> </span><span class="m">1234</span><span class="w"> </span>...
<span class="linenos">14</span><span class="w">  </span>&gt;<span class="w"> </span>initializing<span class="w"> </span>model<span class="w"> </span>parallel<span class="w"> </span>cuda<span class="w"> </span>seeds<span class="w"> </span>on<span class="w"> </span>global<span class="w"> </span>rank<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>model<span class="w"> </span>parallel<span class="w"> </span>rank<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>and<span class="w"> </span>data<span class="w"> </span>parallel<span class="w"> </span>rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>with<span class="w"> </span>model<span class="w"> </span>parallel<span class="w"> </span>seed:<span class="w"> </span><span class="m">3952</span><span class="w"> </span>and<span class="w"> </span>data<span class="w"> </span>parallel<span class="w"> </span>seed:<span class="w"> </span><span class="m">1234</span>
<span class="linenos">15</span><span class="w">  </span>&gt;<span class="w"> </span>compiling<span class="w"> </span>and<span class="w"> </span>loading<span class="w"> </span>fused<span class="w"> </span>kernels<span class="w"> </span>...
<span class="linenos">16</span><span class="w">  </span>Detected<span class="w"> </span>CUDA<span class="w"> </span>files,<span class="w"> </span>patching<span class="w"> </span>ldflags
<span class="linenos">17</span><span class="w">  </span>Emitting<span class="w"> </span>ninja<span class="w"> </span>build<span class="w"> </span>file<span class="w"> </span>/workspace/GWAI/demo/../src/model/denoising/fused_kernels/build/build.ninja...
<span class="linenos">18</span><span class="w">  </span>Building<span class="w"> </span>extension<span class="w"> </span>module<span class="w"> </span>scaled_upper_triang_masked_softmax_cuda...
<span class="linenos">19</span><span class="w">  </span>Allowing<span class="w"> </span>ninja<span class="w"> </span>to<span class="w"> </span><span class="nb">set</span><span class="w"> </span>a<span class="w"> </span>default<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>workers...<span class="w"> </span><span class="o">(</span>overridable<span class="w"> </span>by<span class="w"> </span>setting<span class="w"> </span>the<span class="w"> </span>environment<span class="w"> </span>variable<span class="w"> </span><span class="nv">MAX_JOBS</span><span class="o">=</span>N<span class="o">)</span>
<span class="linenos">20</span><span class="w">  </span>ninja:<span class="w"> </span>no<span class="w"> </span>work<span class="w"> </span>to<span class="w"> </span><span class="k">do</span>.
<span class="linenos">21</span><span class="w">  </span>Loading<span class="w"> </span>extension<span class="w"> </span>module<span class="w"> </span>scaled_upper_triang_masked_softmax_cuda...
<span class="linenos">22</span><span class="w">  </span>Detected<span class="w"> </span>CUDA<span class="w"> </span>files,<span class="w"> </span>patching<span class="w"> </span>ldflags
<span class="linenos">23</span><span class="w">  </span>Emitting<span class="w"> </span>ninja<span class="w"> </span>build<span class="w"> </span>file<span class="w"> </span>/workspace/GWAI/demo/../src/model/denoising/fused_kernels/build/build.ninja...
<span class="linenos">24</span><span class="w">  </span>Building<span class="w"> </span>extension<span class="w"> </span>module<span class="w"> </span>scaled_masked_softmax_cuda...
<span class="linenos">25</span><span class="w">  </span>Allowing<span class="w"> </span>ninja<span class="w"> </span>to<span class="w"> </span><span class="nb">set</span><span class="w"> </span>a<span class="w"> </span>default<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>workers...<span class="w"> </span><span class="o">(</span>overridable<span class="w"> </span>by<span class="w"> </span>setting<span class="w"> </span>the<span class="w"> </span>environment<span class="w"> </span>variable<span class="w"> </span><span class="nv">MAX_JOBS</span><span class="o">=</span>N<span class="o">)</span>
<span class="linenos">26</span><span class="w">  </span>ninja:<span class="w"> </span>no<span class="w"> </span>work<span class="w"> </span>to<span class="w"> </span><span class="k">do</span>.
<span class="linenos">27</span><span class="w">  </span>Loading<span class="w"> </span>extension<span class="w"> </span>module<span class="w"> </span>scaled_masked_softmax_cuda...
<span class="linenos">28</span><span class="w">  </span>Detected<span class="w"> </span>CUDA<span class="w"> </span>files,<span class="w"> </span>patching<span class="w"> </span>ldflags
<span class="linenos">29</span><span class="w">  </span>Emitting<span class="w"> </span>ninja<span class="w"> </span>build<span class="w"> </span>file<span class="w"> </span>/workspace/GWAI/demo/../src/model/denoising/fused_kernels/build/build.ninja...
<span class="linenos">30</span><span class="w">  </span>Building<span class="w"> </span>extension<span class="w"> </span>module<span class="w"> </span>fused_mix_prec_layer_norm_cuda...
<span class="linenos">31</span><span class="w">  </span>Allowing<span class="w"> </span>ninja<span class="w"> </span>to<span class="w"> </span><span class="nb">set</span><span class="w"> </span>a<span class="w"> </span>default<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>workers...<span class="w"> </span><span class="o">(</span>overridable<span class="w"> </span>by<span class="w"> </span>setting<span class="w"> </span>the<span class="w"> </span>environment<span class="w"> </span>variable<span class="w"> </span><span class="nv">MAX_JOBS</span><span class="o">=</span>N<span class="o">)</span>
<span class="linenos">32</span><span class="w">  </span>ninja:<span class="w"> </span>no<span class="w"> </span>work<span class="w"> </span>to<span class="w"> </span><span class="k">do</span>.
<span class="linenos">33</span><span class="w">  </span>Loading<span class="w"> </span>extension<span class="w"> </span>module<span class="w"> </span>fused_mix_prec_layer_norm_cuda...
<span class="linenos">34</span><span class="w">  </span>&gt;&gt;&gt;<span class="w"> </span><span class="k">done</span><span class="w"> </span>with<span class="w"> </span>compiling<span class="w"> </span>and<span class="w"> </span>loading<span class="w"> </span>fused<span class="w"> </span>kernels.<span class="w"> </span>Compilation<span class="w"> </span>time:<span class="w"> </span><span class="m">3</span>.274<span class="w"> </span>seconds
<span class="linenos">35</span><span class="w">  </span><span class="nb">time</span><span class="w"> </span>to<span class="w"> </span>initialize<span class="w"> </span>megatron<span class="w"> </span><span class="o">(</span>seconds<span class="o">)</span>:<span class="w"> </span><span class="m">41</span>.829
<span class="linenos">36</span><span class="w">  </span><span class="o">[</span>after<span class="w"> </span>megatron<span class="w"> </span>is<span class="w"> </span>initialized<span class="o">]</span><span class="w"> </span>datetime:<span class="w"> </span><span class="m">2024</span>-02-02<span class="w"> </span><span class="m">15</span>:50:01
<span class="linenos">37</span><span class="w">  </span>building<span class="w"> </span>WaveFormer<span class="w"> </span>model<span class="w"> </span>...
<span class="linenos">38</span><span class="w">  </span>&gt;<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>parameters<span class="w"> </span>on<span class="w"> </span><span class="o">(</span>tensor,<span class="w"> </span>pipeline<span class="o">)</span><span class="w"> </span>model<span class="w"> </span>parallel<span class="w"> </span>rank<span class="w"> </span><span class="o">(</span><span class="m">0</span>,<span class="w"> </span><span class="m">0</span><span class="o">)</span>:<span class="w"> </span><span class="m">220058673</span>
<span class="linenos">39</span><span class="w">  </span>&gt;<span class="w"> </span>learning<span class="w"> </span>rate<span class="w"> </span>decay<span class="w"> </span>style:<span class="w"> </span>linear
<span class="linenos">40</span><span class="w">  </span>WARNING:<span class="w"> </span>could<span class="w"> </span>not<span class="w"> </span>find<span class="w"> </span>the<span class="w"> </span>metadata<span class="w"> </span>file<span class="w"> </span>demo/latest_checkpointed_iteration.txt
<span class="linenos">41</span><span class="w">     </span>will<span class="w"> </span>not<span class="w"> </span>load<span class="w"> </span>any<span class="w"> </span>checkpoints<span class="w"> </span>and<span class="w"> </span>will<span class="w"> </span>start<span class="w"> </span>from<span class="w"> </span>random
<span class="linenos">42</span><span class="w">  </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>ms<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>load-checkpoint:<span class="w"> </span><span class="m">0</span>.16
<span class="linenos">43</span><span class="w">  </span><span class="o">[</span>after<span class="w"> </span>model,<span class="w"> </span>optimizer,<span class="w"> </span>and<span class="w"> </span>learning<span class="w"> </span>rate<span class="w"> </span>scheduler<span class="w"> </span>are<span class="w"> </span>built<span class="o">]</span><span class="w"> </span>datetime:<span class="w"> </span><span class="m">2024</span>-02-02<span class="w"> </span><span class="m">15</span>:50:01
<span class="linenos">44</span><span class="w">  </span>&gt;<span class="w"> </span>building<span class="w"> </span>train,<span class="w"> </span>validation,<span class="w"> </span>and<span class="w"> </span><span class="nb">test</span><span class="w"> </span>datasets<span class="w"> </span>...
<span class="linenos">45</span><span class="w">  </span>&gt;<span class="w"> </span>building<span class="w"> </span>train,<span class="w"> </span>validation,<span class="w"> </span>and<span class="w"> </span><span class="nb">test</span><span class="w"> </span>datasets<span class="w"> </span><span class="k">for</span><span class="w"> </span>BERT<span class="w"> </span>...
<span class="linenos">46</span><span class="w">  </span>&gt;<span class="w"> </span>finished<span class="w"> </span>creating<span class="w"> </span>BERT<span class="w"> </span>datasets<span class="w"> </span>...
<span class="linenos">47</span><span class="w">  </span><span class="o">[</span>after<span class="w"> </span>dataloaders<span class="w"> </span>are<span class="w"> </span>built<span class="o">]</span><span class="w"> </span>datetime:<span class="w"> </span><span class="m">2024</span>-02-02<span class="w"> </span><span class="m">15</span>:50:06
<span class="linenos">48</span><span class="w">  </span><span class="k">done</span><span class="w"> </span>with<span class="w"> </span>setup<span class="w"> </span>...time<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>model-and-optimizer-setup:<span class="w"> </span><span class="m">111</span>.39<span class="w"> </span><span class="p">|</span><span class="w"> </span>train/valid/test-data-iterators-setup:<span class="w"> </span><span class="m">4415</span>.50
<span class="linenos">49</span>
<span class="linenos">50</span><span class="w">  </span>training<span class="w"> </span>...
<span class="linenos">51</span><span class="w">  </span><span class="o">[</span>before<span class="w"> </span>the<span class="w"> </span>start<span class="w"> </span>of<span class="w"> </span>training<span class="w"> </span>step<span class="o">]</span><span class="w"> </span>datetime:<span class="w"> </span><span class="m">2024</span>-02-02<span class="w"> </span><span class="m">15</span>:50:06
<span class="linenos">52</span><span class="w">  </span>iteration<span class="w">        </span><span class="m">1</span>/<span class="w">   </span><span class="m">30000</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>current<span class="w"> </span>time:<span class="w"> </span><span class="m">1706860208</span>.35<span class="w"> </span><span class="p">|</span><span class="w"> </span>consumed<span class="w"> </span>samples:<span class="w">           </span><span class="m">16</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>elapsed<span class="w"> </span><span class="nb">time</span><span class="w"> </span>per<span class="w"> </span>iteration<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w"> </span><span class="m">1996</span>.1<span class="w"> </span><span class="p">|</span><span class="w"> </span>learning<span class="w"> </span>rate:<span class="w"> </span><span class="m">0</span>.000E+00<span class="w"> </span><span class="p">|</span><span class="w"> </span>global<span class="w"> </span>batch<span class="w"> </span>size:<span class="w">    </span><span class="m">16</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">4294967296</span>.0<span class="w"> </span><span class="p">|</span><span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>skipped<span class="w"> </span>iterations:<span class="w">   </span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>nan<span class="w"> </span>iterations:<span class="w">   </span><span class="m">0</span><span class="w"> </span><span class="p">|</span>
<span class="linenos">53</span><span class="w">  </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>ms<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>backward-compute:<span class="w"> </span><span class="m">138</span>.46<span class="w"> </span><span class="p">|</span><span class="w"> </span>backward-params-all-reduce:<span class="w"> </span><span class="m">32</span>.71<span class="w"> </span><span class="p">|</span><span class="w"> </span>backward-embedding-all-reduce:<span class="w"> </span><span class="m">0</span>.04<span class="w"> </span><span class="p">|</span><span class="w"> </span>optimizer-copy-to-main-grad:<span class="w"> </span><span class="m">3</span>.17<span class="w"> </span><span class="p">|</span><span class="w"> </span>optimizer-unscale-and-check-inf:<span class="w"> </span><span class="m">42</span>.67<span class="w"> </span><span class="p">|</span><span class="w"> </span>optimizer:<span class="w"> </span><span class="m">45</span>.94<span class="w"> </span><span class="p">|</span><span class="w"> </span>batch-generator:<span class="w"> </span><span class="m">263</span>.80
<span class="linenos">54</span><span class="w">  </span>----------------------------------------------------------------------------------------------------
<span class="linenos">55</span><span class="w">  </span>validation<span class="w"> </span>loss<span class="w"> </span>at<span class="w"> </span>iteration<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>lm<span class="w"> </span>loss<span class="w"> </span>value:<span class="w"> </span><span class="m">4</span>.280033E-01<span class="w"> </span><span class="p">|</span><span class="w"> </span>lm<span class="w"> </span>loss<span class="w"> </span>PPL:<span class="w"> </span><span class="m">1</span>.534191E+00<span class="w"> </span><span class="p">|</span>
<span class="linenos">56</span><span class="w">  </span>--------------------------------------------------------------------------------------------
<span class="linenos">57</span><span class="w">  </span>iteration<span class="w">        </span><span class="m">2</span>/<span class="w">   </span><span class="m">30000</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>current<span class="w"> </span>time:<span class="w"> </span><span class="m">1706860208</span>.78<span class="w"> </span><span class="p">|</span><span class="w"> </span>consumed<span class="w"> </span>samples:<span class="w">           </span><span class="m">32</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>elapsed<span class="w"> </span><span class="nb">time</span><span class="w"> </span>per<span class="w"> </span>iteration<span class="w"> </span><span class="o">(</span>ms<span class="o">)</span>:<span class="w"> </span><span class="m">429</span>.4<span class="w"> </span><span class="p">|</span><span class="w"> </span>learning<span class="w"> </span>rate:<span class="w"> </span><span class="m">0</span>.000E+00<span class="w"> </span><span class="p">|</span><span class="w"> </span>global<span class="w"> </span>batch<span class="w"> </span>size:<span class="w">    </span><span class="m">16</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">2147483648</span>.0<span class="w"> </span><span class="p">|</span><span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>skipped<span class="w"> </span>iterations:<span class="w">   </span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>nan<span class="w"> </span>iterations:<span class="w">   </span><span class="m">0</span><span class="w"> </span><span class="p">|</span>
<span class="linenos">58</span><span class="w">  </span><span class="nb">time</span><span class="w"> </span><span class="o">(</span>ms<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>backward-compute:<span class="w"> </span><span class="m">31</span>.50<span class="w"> </span><span class="p">|</span><span class="w"> </span>backward-params-all-reduce:<span class="w"> </span><span class="m">35</span>.43<span class="w"> </span><span class="p">|</span><span class="w"> </span>backward-embedding-all-reduce:<span class="w"> </span><span class="m">0</span>.03<span class="w"> </span><span class="p">|</span><span class="w"> </span>optimizer-copy-to-main-grad:<span class="w"> </span><span class="m">2</span>.87<span class="w"> </span><span class="p">|</span><span class="w"> </span>optimizer-unscale-and-check-inf:<span class="w"> </span><span class="m">12</span>.14<span class="w"> </span><span class="p">|</span><span class="w"> </span>optimizer:<span class="w"> </span><span class="m">15</span>.32<span class="w"> </span><span class="p">|</span><span class="w"> </span>batch-generator:<span class="w"> </span><span class="m">274</span>.37
<span class="linenos">59</span><span class="w">  </span>----------------------------------------------------------------------------------------------------
<span class="linenos">60</span><span class="w">  </span>validation<span class="w"> </span>loss<span class="w"> </span>at<span class="w"> </span>iteration<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>lm<span class="w"> </span>loss<span class="w"> </span>value:<span class="w"> </span><span class="m">4</span>.258614E-01<span class="w"> </span><span class="p">|</span><span class="w"> </span>lm<span class="w"> </span>loss<span class="w"> </span>PPL:<span class="w"> </span><span class="m">1</span>.530909E+00<span class="w"> </span><span class="p">|</span>
<span class="linenos">61</span><span class="w">  </span>--------------------------------------------------------------------------------------------
</pre></div>
</div>
</section>
<section id="signal-detection">
<h2>Signal Detection<a class="headerlink" href="#signal-detection" title="Link to this heading"></a></h2>
<p>Firstly, activating <code class="docutils literal notranslate"><span class="pre">waveform</span></code> environment.
Then, by running <a class="reference external" href="https://github.com/AI-HPC-Research-Team/GWAI/tree/main/demos/train_detection.py">train_detection.py</a> script, your own detection model can be trained.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>conda<span class="w"> </span>activate<span class="w"> </span>waveform
<span class="linenos">2</span><span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>/workspace/GWAI/
<span class="linenos">3</span><span class="gp">$ </span>python<span class="w"> </span>demos/train_detection.py<span class="w"> </span>configs/detection.yaml
</pre></div>
</div>
<p>You can modify <cite>detection.yaml</cite> to define your own training dataset as well as model configurations. For example:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="c1"># Basic parameters</span>
<span class="linenos">  2</span><span class="c1"># Seed needs to be set at top of yaml, before objects with parameters are made</span>
<span class="linenos">  3</span><span class="c1">#</span>
<span class="linenos">  4</span><span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1607</span>
<span class="linenos">  5</span><span class="nt">__set_seed</span><span class="p">:</span><span class="w"> </span><span class="kt">!apply:torch.manual_seed</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="kt">!ref</span><span class="w"> </span><span class="nv">&lt;seed&gt;</span><span class="p p-Indicator">]</span>
<span class="linenos">  6</span>
<span class="linenos">  7</span><span class="c1"># cuda device num</span>
<span class="linenos">  8</span><span class="nt">cuda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="linenos">  9</span><span class="c1"># Data params</span>
<span class="linenos"> 10</span><span class="nt">data_folder</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;./datasets/detection&#39;</span>
<span class="linenos"> 11</span><span class="nt">data_hdf5</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">smbhb_test.hdf5</span>
<span class="linenos"> 12</span><span class="nt">noise_hdf5</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">noise_test.hdf5</span>
<span class="linenos"> 13</span>
<span class="linenos"> 14</span><span class="nt">experiment_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">detection_demo</span>
<span class="linenos"> 15</span><span class="c1">#----------------------------------------</span>
<span class="linenos"> 16</span>
<span class="linenos"> 17</span><span class="nt">output_folder</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">results/&lt;experiment_name&gt;/&lt;seed&gt;</span>
<span class="linenos"> 18</span><span class="nt">train_log</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;output_folder&gt;/train_log.txt</span>
<span class="linenos"> 19</span><span class="nt">save_folder</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;output_folder&gt;/save</span>
<span class="linenos"> 20</span>
<span class="linenos"> 21</span><span class="c1"># Experiment params</span>
<span class="linenos"> 22</span><span class="nt">auto_mix_prec</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos"> 23</span><span class="nt">test_only</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos"> 24</span><span class="nt">num_spks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="linenos"> 25</span><span class="nt">progressbar</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 26</span><span class="nt">save_inf_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos"> 27</span><span class="nt">save_attention_weights</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos"> 28</span><span class="c1"># se loss * alpha + clsf loss * (1 - alpha)</span>
<span class="linenos"> 29</span><span class="nt">alpha</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="linenos"> 30</span><span class="nt">inf_data</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;save_folder&gt;/inf_test/</span>
<span class="linenos"> 31</span><span class="c1"># att_data: !ref &lt;save_folder&gt;/inf_test/</span>
<span class="linenos"> 32</span>
<span class="linenos"> 33</span><span class="c1"># Training parameters</span>
<span class="linenos"> 34</span><span class="nt">N_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="linenos"> 35</span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="linenos"> 36</span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0005</span>
<span class="linenos"> 37</span><span class="nt">clip_grad_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="linenos"> 38</span><span class="nt">loss_upper_lim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">999999</span><span class="w">  </span><span class="c1"># this is the upper limit for an acceptable loss</span>
<span class="linenos"> 39</span><span class="c1"># if True, the training sequences are cut to a specified length</span>
<span class="linenos"> 40</span><span class="nt">limit_training_signal_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos"> 41</span><span class="c1"># this is the length of sequences if we choose to limit</span>
<span class="linenos"> 42</span><span class="c1"># the signal length of training sequences</span>
<span class="linenos"> 43</span><span class="nt">training_signal_len</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4000</span>
<span class="linenos"> 44</span><span class="nt">dataloader_opts</span><span class="p">:</span>
<span class="linenos"> 45</span><span class="w">    </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;batch_size&gt;</span>
<span class="linenos"> 46</span><span class="w">    </span><span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="linenos"> 47</span>
<span class="linenos"> 48</span><span class="c1"># loss thresholding -- this thresholds the training loss</span>
<span class="linenos"> 49</span><span class="nt">threshold_byloss</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 50</span><span class="nt">threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-50</span>
<span class="linenos"> 51</span>
<span class="linenos"> 52</span><span class="c1"># Encoder parameters</span>
<span class="linenos"> 53</span><span class="nt">N_encoder_out</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="linenos"> 54</span><span class="nt">out_channels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="linenos"> 55</span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="linenos"> 56</span><span class="nt">kernel_stride</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="linenos"> 57</span>
<span class="linenos"> 58</span>
<span class="linenos"> 59</span><span class="c1"># Specifying the network</span>
<span class="linenos"> 60</span><span class="nt">Encoder</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.lobes.models.dual_path.Encoder</span>
<span class="linenos"> 61</span><span class="w">    </span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;kernel_size&gt;</span>
<span class="linenos"> 62</span><span class="w">    </span><span class="nt">out_channels</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;N_encoder_out&gt;</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span>
<span class="linenos"> 65</span><span class="nt">SBtfintra</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.lobes.models.dual_path.SBTransformerBlock</span>
<span class="linenos"> 66</span><span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos"> 67</span><span class="w">    </span><span class="nt">d_model</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;out_channels&gt;</span>
<span class="linenos"> 68</span><span class="w">    </span><span class="nt">nhead</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="linenos"> 69</span><span class="w">    </span><span class="nt">d_ffn</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="linenos"> 70</span><span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="linenos"> 71</span><span class="w">    </span><span class="nt">use_positional_encoding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 72</span><span class="w">    </span><span class="nt">norm_before</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 73</span>
<span class="linenos"> 74</span><span class="nt">SBtfinter</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.lobes.models.dual_path.SBTransformerBlock</span>
<span class="linenos"> 75</span><span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos"> 76</span><span class="w">    </span><span class="nt">d_model</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;out_channels&gt;</span>
<span class="linenos"> 77</span><span class="w">    </span><span class="nt">nhead</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="linenos"> 78</span><span class="w">    </span><span class="nt">d_ffn</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="linenos"> 79</span><span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="linenos"> 80</span><span class="w">    </span><span class="nt">use_positional_encoding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 81</span><span class="w">    </span><span class="nt">norm_before</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 82</span>
<span class="linenos"> 83</span><span class="nt">MaskNet</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.lobes.models.dual_path.Dual_Path_Model</span>
<span class="linenos"> 84</span><span class="w">    </span><span class="nt">num_spks</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;num_spks&gt;</span>
<span class="linenos"> 85</span><span class="w">    </span><span class="nt">in_channels</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;N_encoder_out&gt;</span>
<span class="linenos"> 86</span><span class="w">    </span><span class="nt">out_channels</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;out_channels&gt;</span>
<span class="linenos"> 87</span><span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos"> 88</span><span class="w">    </span><span class="nt">K</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">25</span>
<span class="linenos"> 89</span><span class="w">    </span><span class="nt">intra_model</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;SBtfintra&gt;</span>
<span class="linenos"> 90</span><span class="w">    </span><span class="nt">inter_model</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;SBtfinter&gt;</span>
<span class="linenos"> 91</span><span class="w">    </span><span class="nt">norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ln</span>
<span class="linenos"> 92</span><span class="w">    </span><span class="nt">linear_layer_after_inter_intra</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos"> 93</span><span class="w">    </span><span class="nt">skip_around_intra</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="linenos"> 94</span>
<span class="linenos"> 95</span><span class="nt">Decoder</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.lobes.models.dual_path.Decoder</span>
<span class="linenos"> 96</span><span class="w">    </span><span class="nt">in_channels</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;N_encoder_out&gt;</span>
<span class="linenos"> 97</span><span class="w">    </span><span class="nt">out_channels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="linenos"> 98</span><span class="w">    </span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;kernel_size&gt;</span>
<span class="linenos"> 99</span><span class="w">    </span><span class="nt">stride</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;kernel_stride&gt;</span>
<span class="linenos">100</span><span class="w">    </span><span class="nt">bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="linenos">101</span>
<span class="linenos">102</span><span class="nt">linear_1</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.nnet.linear.Linear</span>
<span class="linenos">103</span><span class="w">    </span><span class="nt">input_size</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;training_signal_len&gt;</span>
<span class="linenos">104</span><span class="w">    </span><span class="nt">n_neurons</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="linenos">105</span>
<span class="linenos">106</span><span class="nt">relu</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:torch.nn.ReLU</span>
<span class="linenos">107</span>
<span class="linenos">108</span><span class="nt">linear_2</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.nnet.linear.Linear</span>
<span class="linenos">109</span><span class="w">    </span><span class="nt">input_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="linenos">110</span><span class="w">    </span><span class="nt">n_neurons</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="linenos">111</span>
<span class="linenos">112</span><span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="kt">!name:torch.optim.Adam</span>
<span class="linenos">113</span><span class="w">    </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;lr&gt;</span>
<span class="linenos">114</span><span class="w">    </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="linenos">115</span>
<span class="linenos">116</span>
<span class="linenos">117</span><span class="nt">loss</span><span class="p">:</span><span class="w"> </span><span class="kt">!name:speechbrain.nnet.losses.get_si_snr_with_pitwrapper</span>
<span class="linenos">118</span><span class="nt">loss2</span><span class="p">:</span><span class="w"> </span><span class="kt">!name:speechbrain.nnet.losses.bce_loss</span>
<span class="linenos">119</span>
<span class="linenos">120</span><span class="nt">lr_scheduler</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.nnet.schedulers.ReduceLROnPlateau</span>
<span class="linenos">121</span><span class="w">    </span><span class="nt">factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="linenos">122</span><span class="w">    </span><span class="nt">patience</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos">123</span><span class="w">    </span><span class="nt">dont_halve_until_epoch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">35</span>
<span class="linenos">124</span>
<span class="linenos">125</span><span class="nt">epoch_counter</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.utils.epoch_loop.EpochCounter</span>
<span class="linenos">126</span><span class="w">    </span><span class="nt">limit</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;N_epochs&gt;</span>
<span class="linenos">127</span>
<span class="linenos">128</span><span class="nt">modules</span><span class="p">:</span>
<span class="linenos">129</span><span class="w">    </span><span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;Encoder&gt;</span>
<span class="linenos">130</span><span class="w">    </span><span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;Decoder&gt;</span>
<span class="linenos">131</span><span class="w">    </span><span class="nt">masknet</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;MaskNet&gt;</span>
<span class="linenos">132</span><span class="w">    </span><span class="nt">linear_1</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;linear_1&gt;</span>
<span class="linenos">133</span><span class="w">    </span><span class="nt">linear_2</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;linear_2&gt;</span>
<span class="linenos">134</span>
<span class="linenos">135</span><span class="nt">checkpointer</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.utils.checkpoints.Checkpointer</span>
<span class="linenos">136</span><span class="w">    </span><span class="nt">checkpoints_dir</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;save_folder&gt;</span>
<span class="linenos">137</span><span class="w">    </span><span class="nt">recoverables</span><span class="p">:</span>
<span class="linenos">138</span><span class="w">        </span><span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;Encoder&gt;</span>
<span class="linenos">139</span><span class="w">        </span><span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;Decoder&gt;</span>
<span class="linenos">140</span><span class="w">        </span><span class="nt">masknet</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;MaskNet&gt;</span>
<span class="linenos">141</span><span class="w">        </span><span class="nt">linear_1</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;linear_1&gt;</span>
<span class="linenos">142</span><span class="w">        </span><span class="nt">linear_2</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;linear_2&gt;</span>
<span class="linenos">143</span><span class="w">        </span><span class="nt">counter</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;epoch_counter&gt;</span>
<span class="linenos">144</span><span class="w">        </span><span class="nt">lr_scheduler</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;lr_scheduler&gt;</span>
<span class="linenos">145</span><span class="w">        </span><span class="c1"># mlp: !ref &lt;MLP&gt;</span>
<span class="linenos">146</span>
<span class="linenos">147</span><span class="nt">train_logger</span><span class="p">:</span><span class="w"> </span><span class="kt">!new:speechbrain.utils.train_logger.FileTrainLogger</span>
<span class="linenos">148</span><span class="w">    </span><span class="nt">save_file</span><span class="p">:</span><span class="w"> </span><span class="kt">!ref</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;train_log&gt;</span>
</pre></div>
</div>
<p>The output log can be seen as follows.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w">  </span>speechbrain.core<span class="w"> </span>-<span class="w"> </span>Beginning<span class="w"> </span>experiment!
<span class="linenos"> 2</span><span class="w">  </span>speechbrain.core<span class="w"> </span>-<span class="w"> </span>Experiment<span class="w"> </span>folder:<span class="w"> </span>results/detection_demo22/1607
<span class="linenos"> 3</span><span class="w">  </span>speechbrain.core<span class="w"> </span>-<span class="w"> </span>Info:<span class="w"> </span>test_only<span class="w"> </span>arg<span class="w"> </span>overridden<span class="w"> </span>by<span class="w"> </span><span class="nb">command</span><span class="w"> </span>line<span class="w"> </span>input<span class="w"> </span>to:<span class="w"> </span>False
<span class="linenos"> 4</span><span class="w">  </span>speechbrain.core<span class="w"> </span>-<span class="w"> </span>Info:<span class="w"> </span>auto_mix_prec<span class="w"> </span>arg<span class="w"> </span>from<span class="w"> </span>hparam<span class="w"> </span>file<span class="w"> </span>is<span class="w"> </span>used
<span class="linenos"> 5</span><span class="w">  </span>speechbrain.core<span class="w"> </span>-<span class="w"> </span><span class="m">5</span>.6M<span class="w"> </span>trainable<span class="w"> </span>parameters<span class="w"> </span><span class="k">in</span><span class="w"> </span>Separation
<span class="linenos"> 6</span><span class="w">  </span>speechbrain.utils.checkpoints<span class="w"> </span>-<span class="w"> </span>Would<span class="w"> </span>load<span class="w"> </span>a<span class="w"> </span>checkpoint<span class="w"> </span>here,<span class="w"> </span>but<span class="w"> </span>none<span class="w"> </span>found<span class="w"> </span>yet.
<span class="linenos"> 7</span><span class="w">  </span>speechbrain.utils.epoch_loop<span class="w"> </span>-<span class="w"> </span>Going<span class="w"> </span>into<span class="w"> </span>epoch<span class="w"> </span><span class="m">1</span>
<span class="linenos"> 8</span><span class="w">  </span><span class="m">100</span>%<span class="p">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">13</span>/13<span class="w"> </span><span class="o">[</span><span class="m">00</span>:02&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">5</span>.45it/s,<span class="w"> </span><span class="nv">loss1</span><span class="o">=</span><span class="m">6</span>.18,<span class="w"> </span><span class="nv">loss2</span><span class="o">=</span><span class="m">0</span>.693,<span class="w"> </span><span class="nv">train_loss</span><span class="o">=</span><span class="m">6</span>.18<span class="o">]</span>
<span class="linenos"> 9</span><span class="w">  </span><span class="m">100</span>%<span class="p">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">3</span>/3<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">3</span>.50it/s<span class="o">]</span>
<span class="linenos">10</span><span class="w">  </span>speechbrain.utils.train_logger<span class="w"> </span>-<span class="w"> </span>epoch:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>lr:<span class="w"> </span><span class="m">5</span>.00e-04<span class="w"> </span>-<span class="w"> </span>train<span class="w"> </span>si-snr:<span class="w"> </span><span class="m">6</span>.18,<span class="w"> </span>train<span class="w"> </span>loss1:<span class="w"> </span><span class="m">6</span>.18,<span class="w"> </span>train<span class="w"> </span>loss2:<span class="w"> </span><span class="m">6</span>.93e-01<span class="w"> </span>-<span class="w"> </span>valid<span class="w"> </span>si-snr:<span class="w"> </span>-6.32e-01,<span class="w"> </span>valid<span class="w"> </span>loss1:<span class="w"> </span>-6.32e-01,<span class="w"> </span>valid<span class="w"> </span>loss2:<span class="w"> </span><span class="m">6</span>.96e-01
<span class="linenos">11</span><span class="w">  </span>speechbrain.utils.checkpoints<span class="w"> </span>-<span class="w"> </span>Saved<span class="w"> </span>an<span class="w"> </span>end-of-epoch<span class="w"> </span>checkpoint<span class="w"> </span><span class="k">in</span><span class="w"> </span>results/detection_demo22/1607/save/CKPT+2024-02-02+15-55-58+00
<span class="linenos">12</span><span class="w">  </span>speechbrain.utils.epoch_loop<span class="w"> </span>-<span class="w"> </span>Going<span class="w"> </span>into<span class="w"> </span>epoch<span class="w"> </span><span class="m">2</span>
<span class="linenos">13</span><span class="w">  </span><span class="m">100</span>%<span class="p">|</span>██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">13</span>/13<span class="w"> </span><span class="o">[</span><span class="m">00</span>:02&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">5</span>.72it/s,<span class="w"> </span><span class="nv">loss1</span><span class="o">=</span>-2.26,<span class="w"> </span><span class="nv">loss2</span><span class="o">=</span><span class="m">0</span>.693,<span class="w"> </span><span class="nv">train_loss</span><span class="o">=</span>-2.26<span class="o">]</span>
<span class="linenos">14</span><span class="w">  </span><span class="m">100</span>%<span class="p">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="p">|</span><span class="w"> </span><span class="m">3</span>/3<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;<span class="m">00</span>:00,<span class="w">  </span><span class="m">3</span>.47it/s<span class="o">]</span>
<span class="linenos">15</span><span class="w">  </span>speechbrain.utils.train_logger<span class="w"> </span>-<span class="w"> </span>epoch:<span class="w"> </span><span class="m">2</span>,<span class="w"> </span>lr:<span class="w"> </span><span class="m">5</span>.00e-04<span class="w"> </span>-<span class="w"> </span>train<span class="w"> </span>si-snr:<span class="w"> </span>-2.26e+00,<span class="w"> </span>train<span class="w"> </span>loss1:<span class="w"> </span>-2.26e+00,<span class="w"> </span>train<span class="w"> </span>loss2:<span class="w"> </span><span class="m">6</span>.93e-01<span class="w"> </span>-<span class="w"> </span>valid<span class="w"> </span>si-snr:<span class="w"> </span>-2.13e+00,<span class="w"> </span>valid<span class="w"> </span>loss1:<span class="w"> </span>-2.13e+00,<span class="w"> </span>valid<span class="w"> </span>loss2:<span class="w"> </span><span class="m">6</span>.97e-01
<span class="linenos">16</span><span class="w">  </span>speechbrain.utils.checkpoints<span class="w"> </span>-<span class="w"> </span>Saved<span class="w"> </span>an<span class="w"> </span>end-of-epoch<span class="w"> </span>checkpoint<span class="w"> </span><span class="k">in</span><span class="w"> </span>results/detection_demo22/1607/save/CKPT+2024-02-02+15-56-01+00
<span class="linenos">17</span><span class="w">  </span>speechbrain.utils.checkpoints<span class="w"> </span>-<span class="w"> </span>Deleted<span class="w"> </span>checkpoint<span class="w"> </span><span class="k">in</span><span class="w"> </span>results/detection_demo22/1607/save/CKPT+2024-02-02+15-55-58+00
<span class="linenos">18</span><span class="w">  </span>speechbrain.utils.epoch_loop<span class="w"> </span>-<span class="w"> </span>Going<span class="w"> </span>into<span class="w"> </span>epoch<span class="w"> </span><span class="m">3</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="waveform.html" class="btn btn-neutral float-left" title="Examples of space-based gravitational wave signal generation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="evaluation.html" class="btn btn-neutral float-right" title="Examples of evaluation method" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Yue Zhou, Tianyu Zhao.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>