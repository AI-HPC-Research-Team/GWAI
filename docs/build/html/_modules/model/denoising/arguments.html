<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>model.denoising.arguments &mdash; GWAI  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            GWAI
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../about_gwai.html">About GWAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules.html">Main Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../citations.html">Citations</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">GWAI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
          <li class="breadcrumb-item"><a href="../../model.html">model</a></li>
          <li class="breadcrumb-item"><a href="../denoising.html">model.denoising</a></li>
      <li class="breadcrumb-item active">model.denoising.arguments</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for model.denoising.arguments</h1><div class="highlight"><pre>
<span></span><span class="c1"># coding=utf-8</span>
<span class="c1"># Copyright (c) 2022, PengCheng Laboratory.  All rights reserved.</span>
<span class="c1"># Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>
<span class="c1"># Most of the code here has been copied from:</span>
<span class="c1">#   https://github.com/NVIDIA/Megatron-LM/blob/v2.5/megatron/arguments.py</span>
<span class="c1"># with some modifications.</span>

<span class="sd">&quot;&quot;&quot;Megatron arguments.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">torch</span>


<div class="viewcode-block" id="parse_args">
<a class="viewcode-back" href="../../../model.denoising.html#model.denoising.arguments.parse_args">[docs]</a>
<span class="k">def</span> <span class="nf">parse_args</span><span class="p">(</span><span class="n">extra_args_provider</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">defaults</span><span class="o">=</span><span class="p">{},</span> <span class="n">ignore_unknown_args</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse all arguments.&quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Megatron-GW Arguments&quot;</span><span class="p">,</span> <span class="n">allow_abbrev</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="c1"># Standard arguments.</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_network_size_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_regularization_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_training_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_initialization_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_learning_rate_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_checkpointing_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_mixed_precision_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_distributed_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_validation_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_data_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_autoresume_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="c1"># parser = _add_biencoder_args(parser)</span>
    <span class="c1"># parser = _add_vit_args(parser)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">_add_logging_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>

    <span class="c1"># Custom arguments.</span>
    <span class="k">if</span> <span class="n">extra_args_provider</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">parser</span> <span class="o">=</span> <span class="n">extra_args_provider</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>

    <span class="c1"># Parse.</span>
    <span class="k">if</span> <span class="n">ignore_unknown_args</span><span class="p">:</span>
        <span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># Distributed args.</span>
    <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">))</span>
    <span class="n">args</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">))</span>
    <span class="c1"># Tensor model parallel size.</span>
    <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
        <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">world_size</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">world_size</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
        <span class="s2">&quot;world size&quot;</span> <span class="s2">&quot; (</span><span class="si">{}</span><span class="s2">) is not divisible by tensor model parallel size (</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Pipeline model parallel size.</span>
    <span class="n">args</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
        <span class="n">args</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span><span class="p">,</span>
        <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">world_size</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="c1"># Checks.</span>
    <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">args</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">world_size</span> <span class="o">%</span> <span class="n">model_parallel_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
        <span class="s2">&quot;world size is not&quot;</span>
        <span class="s2">&quot; divisible by tensor parallel size (</span><span class="si">{}</span><span class="s2">) times pipeline parallel &quot;</span>
        <span class="s2">&quot;size (</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span>
            <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">args</span><span class="o">.</span><span class="n">data_parallel_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">world_size</span> <span class="o">//</span> <span class="n">model_parallel_size</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;using world size: </span><span class="si">{}</span><span class="s2">, data-parallel-size: </span><span class="si">{}</span><span class="s2">, &quot;</span>
            <span class="s2">&quot;tensor-model-parallel size: </span><span class="si">{}</span><span class="s2">, &quot;</span>
            <span class="s2">&quot;pipeline-model-parallel size: </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">args</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span>
                <span class="n">args</span><span class="o">.</span><span class="n">data_parallel_size</span><span class="p">,</span>
                <span class="n">args</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span><span class="p">,</span>
                <span class="n">args</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Deprecated arguments</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
        <span class="s2">&quot;--batch-size argument is no longer &quot;</span> <span class="s2">&quot;valid, use --micro-batch-size instead&quot;</span>
    <span class="p">)</span>
    <span class="k">del</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">warmup</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
        <span class="s2">&quot;--warmup argument is no longer valid, use &quot;</span> <span class="s2">&quot;--lr-warmup-fraction instead&quot;</span>
    <span class="p">)</span>
    <span class="k">del</span> <span class="n">args</span><span class="o">.</span><span class="n">warmup</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">model_parallel_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
        <span class="s2">&quot;--model-parallel-size is no &quot;</span>
        <span class="s2">&quot;longer valid, use --tensor-model-parallel-size instead&quot;</span>
    <span class="p">)</span>
    <span class="k">del</span> <span class="n">args</span><span class="o">.</span><span class="n">model_parallel_size</span>

    <span class="c1"># Set input defaults.</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">defaults</span><span class="p">:</span>
        <span class="c1"># For default to be valid, it should not be provided in the</span>
        <span class="c1"># arguments that are passed to the program. We check this by</span>
        <span class="c1"># ensuring the arg is set to None.</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;WARNING: overriding default arguments for </span><span class="si">{key}</span><span class="s2">:</span><span class="si">{v}</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">                       with </span><span class="si">{key}</span><span class="s2">:</span><span class="si">{v2}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">defaults</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">v2</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
                    <span class="p">),</span>
                    <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">defaults</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>

    <span class="c1"># Batch size.</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">micro_batch_size</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">global_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">global_batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">micro_batch_size</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">data_parallel_size</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;setting global batch size to </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">global_batch_size</span><span class="p">),</span>
                <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">global_batch_size</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers_per_virtual_pipeline_stage</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;pipeline-model-parallel size should be greater than 2 with &quot;</span>
            <span class="s2">&quot;interleaved schedule&quot;</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers_per_virtual_pipeline_stage</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;number of layers is not divisible by number of layers per virtual &quot;</span>
            <span class="s2">&quot;pipeline stage&quot;</span>
        <span class="p">)</span>
        <span class="n">args</span><span class="o">.</span><span class="n">virtual_pipeline_model_parallel_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span>
        <span class="p">)</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers_per_virtual_pipeline_stage</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">virtual_pipeline_model_parallel_size</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Parameters dtype.</span>
    <span class="n">args</span><span class="o">.</span><span class="n">params_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">fp16</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">bf16</span>
        <span class="n">args</span><span class="o">.</span><span class="n">params_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">half</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">fp16</span>
        <span class="n">args</span><span class="o">.</span><span class="n">params_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
        <span class="c1"># bfloat16 requires gradient accumulation and all-reduce to</span>
        <span class="c1"># be done in fp32.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">accumulate_allreduce_grads_in_fp32</span><span class="p">:</span>
            <span class="n">args</span><span class="o">.</span><span class="n">accumulate_allreduce_grads_in_fp32</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;accumulate and all-reduce gradients in fp32 for &quot;</span>
                    <span class="s2">&quot;bfloat16 data type.&quot;</span><span class="p">,</span>
                    <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;using </span><span class="si">{}</span><span class="s2"> for parameters ...&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">params_dtype</span><span class="p">),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># If we do accumulation and all-reduces in fp32, we need to have</span>
    <span class="c1"># local DDP and we should set the use-contiguous-buffers-in-ddp.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">accumulate_allreduce_grads_in_fp32</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">DDP_impl</span> <span class="o">==</span> <span class="s2">&quot;local&quot;</span>
        <span class="n">args</span><span class="o">.</span><span class="n">use_contiguous_buffers_in_ddp</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dataloader_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">dataloader_type</span> <span class="o">=</span> <span class="s2">&quot;single&quot;</span>

    <span class="c1"># Consumed tokens.</span>
    <span class="n">args</span><span class="o">.</span><span class="n">consumed_train_samples</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">args</span><span class="o">.</span><span class="n">consumed_valid_samples</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Iteration-based training.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">train_iters</span><span class="p">:</span>
        <span class="c1"># If we use iteration-based training, make sure the</span>
        <span class="c1"># sample-based options are off.</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">train_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expected iteration-based training&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">lr_decay_samples</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;expected iteration-based learning rate decay&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_samples</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;expected iteration-based learning rate warmup&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">rampup_batch_size</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;expected no batch-size rampup for iteration-based training&quot;</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_fraction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_iters</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;can only specify one of lr-warmup-fraction and lr-warmup-iters&quot;</span>

    <span class="c1"># Sample-based training.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">train_samples</span><span class="p">:</span>
        <span class="c1"># If we use sample-based training, make sure the</span>
        <span class="c1"># iteration-based options are off.</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">train_iters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expected sample-based training&quot;</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">lr_decay_iters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;expected sample-based learning rate decay&quot;</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_iters</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;expected sample-based learnig rate warmup&quot;</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_fraction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_samples</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
                <span class="s2">&quot;can only specify one of lr-warmup-fraction &quot;</span> <span class="s2">&quot;and lr-warmup-samples&quot;</span>
            <span class="p">)</span>

    <span class="c1"># Check required arguments.</span>
    <span class="n">required_args</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;num_layers&quot;</span><span class="p">,</span>
        <span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;num_attention_heads&quot;</span><span class="p">,</span>
        <span class="s2">&quot;max_position_embeddings&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">req_arg</span> <span class="ow">in</span> <span class="n">required_args</span><span class="p">:</span>
        <span class="n">_check_arg_is_not_none</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">req_arg</span><span class="p">)</span>

    <span class="c1"># Checks.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">ffn_hidden_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">ffn_hidden_size</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">kv_channels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">args</span><span class="o">.</span><span class="n">kv_channels</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">seq_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">encoder_seq_length</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="n">args</span><span class="o">.</span><span class="n">encoder_seq_length</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">seq_length</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">encoder_seq_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">args</span><span class="o">.</span><span class="n">seq_length</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">encoder_seq_length</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">seq_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">&gt;=</span> <span class="n">args</span><span class="o">.</span><span class="n">seq_length</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">decoder_seq_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">&gt;=</span> <span class="n">args</span><span class="o">.</span><span class="n">decoder_seq_length</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">min_lr</span> <span class="o">&lt;=</span> <span class="n">args</span><span class="o">.</span><span class="n">lr</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">save</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">save_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="c1"># Mixed precision checks.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">fp16_lm_cross_entropy</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">fp16</span><span class="p">,</span> <span class="s2">&quot;lm cross entropy in fp16 only support in fp16 mode.&quot;</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">fp32_residual_connection</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">args</span><span class="o">.</span><span class="n">fp16</span> <span class="ow">or</span> <span class="n">args</span><span class="o">.</span><span class="n">bf16</span>
        <span class="p">),</span> <span class="s2">&quot;residual connection in fp32 only supported when using fp16 or bf16.&quot;</span>
    <span class="c1"># Activation checkpointing.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">distribute_checkpointed_activations</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span class="n">checkpoint_activations</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;for distribute-checkpointed-activations to work you &quot;</span>
            <span class="s2">&quot;need to enable checkpoint-activations&quot;</span>
        <span class="p">)</span>

    <span class="n">_print_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">args</span></div>



<span class="k">def</span> <span class="nf">_print_args</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print arguments.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------ arguments ------------------------&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">str_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
            <span class="n">dots</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span> <span class="o">*</span> <span class="p">(</span><span class="mi">48</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">arg</span><span class="p">))</span>
            <span class="n">str_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;  </span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">dots</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">arg</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">str_list</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">()):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------------- end of arguments ---------------------&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_arg_is_not_none</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">arg</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> argument is None&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_add_network_size_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;network size&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-layers&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of transformer layers.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--hidden-size&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Tansformer hidden size.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--ffn-hidden-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Transformer Feed-Forward Network hidden size. &quot;</span>
        <span class="s2">&quot;This is set to 4*hidden-size if not provided&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-attention-heads&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of transformer attention heads.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--kv-channels&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Projection weights dimension in multi-head &quot;</span>
        <span class="s2">&quot;attention. This is set to &quot;</span>
        <span class="s2">&quot;   args.hidden_size // args.num_attention_heads &quot;</span>
        <span class="s2">&quot;if not provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--max-position-embeddings&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum number of position embeddings to use. &quot;</span>
        <span class="s2">&quot;This is the size of position embedding.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--make-vocab-size-divisible-by&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Pad the vocab size to be divisible by this value.&quot;</span>
        <span class="s2">&quot;This is added for computational efficieny reasons.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--layernorm-epsilon&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Layer norm epsilon.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--apply-residual-connection-post-layernorm&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, use original BERT residula connection &quot;</span> <span class="s2">&quot;ordering.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--openai-gelu&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use OpenAIs GeLU implementation. This option&quot;</span>
        <span class="s2">&quot;should not be used unless for backward compatibility&quot;</span>
        <span class="s2">&quot;reasons.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--onnx-safe&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use workarounds for known problems with &quot;</span> <span class="s2">&quot;Torch ONNX exporter&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-binary-head&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Disable binary head.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;binary_head&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_logging_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;logging&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-params-norm&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, calculate and log parameters norm.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-num-zeros-in-grad&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, calculate and log the number of zeros in gradient.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tensorboard-log-interval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Report to tensorboard interval.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tensorboard-queue-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Size of the tensorboard queue for pending events &quot;</span>
        <span class="s2">&quot;and summaries before one of the ‘add’ calls forces a &quot;</span>
        <span class="s2">&quot;flush to disk.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-timers-to-tensorboard&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, write timers to tensorboard.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-batch-size-to-tensorboard&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, write batch-size to tensorboard.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-log-learnig-rate-to-tensorboard&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Disable learning rate logging to tensorboard.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;log_learning_rate_to_tensorboard&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-log-loss-scale-to-tensorboard&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Disable loss-scale logging to tensorboard.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;log_loss_scale_to_tensorboard&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-validation-ppl-to-tensorboard&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, write validation perplexity to &quot;</span> <span class="s2">&quot;tensorboard.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-memory-to-tensorboard&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable memory logging to tensorboard.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_regularization_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;regularization&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--attention-dropout&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Post attention dropout probability.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--hidden-dropout&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Dropout probability for hidden state transformer.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--weight-decay&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Weight decay coefficient for L2 regularization.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--clip-grad&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Gradient clipping based on global L2 norm.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--adam-beta1&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;First coefficient for computing running averages &quot;</span>
        <span class="s2">&quot;of gradient and its square&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--adam-beta2&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Second coefficient for computing running averages &quot;</span>
        <span class="s2">&quot;of gradient and its square&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--adam-eps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Term added to the denominator to improve&quot;</span> <span class="s2">&quot;numerical stability of adam&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lamb-eps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Term added to the denominator to improve&quot;</span> <span class="s2">&quot;numerical stability of lamb&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--sgd-momentum&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Momentum factor for sgd&quot;</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_training_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--micro-batch-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Batch size per model instance (local batch size). &quot;</span>
        <span class="s2">&quot;Global batch size is local batch size times data &quot;</span>
        <span class="s2">&quot;parallel size times number of micro batches.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--batch-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Old batch size parameter, do not use. &quot;</span> <span class="s2">&quot;Use --micro-batch-size instead&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--global-batch-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Training batch size. If set, it should be a &quot;</span>
        <span class="s2">&quot;multiple of micro-batch-size times data-parallel-size. &quot;</span>
        <span class="s2">&quot;If this value is None, then &quot;</span>
        <span class="s2">&quot;use micro-batch-size * data-parallel-size as the &quot;</span>
        <span class="s2">&quot;global batch size. This choice will result in 1 for &quot;</span>
        <span class="s2">&quot;number of micro-batches.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--rampup-batch-size&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Batch size ramp up with the following values:&quot;</span>
        <span class="s2">&quot;  --rampup-batch-size &lt;start batch size&gt; &quot;</span>
        <span class="s2">&quot;                      &lt;batch size incerement&gt; &quot;</span>
        <span class="s2">&quot;                      &lt;ramp-up samples&gt; &quot;</span>
        <span class="s2">&quot;For example:&quot;</span>
        <span class="s2">&quot;   --rampup-batch-size 16 8 300000 \ &quot;</span>
        <span class="s2">&quot;   --global-batch-size 1024&quot;</span>
        <span class="s2">&quot;will start with global batch size 16 and over &quot;</span>
        <span class="s2">&quot; (1024 - 16) / 8 = 126 intervals will increase&quot;</span>
        <span class="s2">&quot;the batch size linearly to 1024. In each interval&quot;</span>
        <span class="s2">&quot;we will use approximately 300000 / 126 = 2380 samples.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--checkpoint-activations&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Checkpoint activation to allow for training &quot;</span>
        <span class="s2">&quot;with larger models, sequences, and batch sizes.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--distribute-checkpointed-activations&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, distribute checkpointed activations &quot;</span>
        <span class="s2">&quot;across model parallel group.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--checkpoint-num-layers&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;chunk size (number of layers) for checkpointing.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--train-iters&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Total number of iterations to train over all &quot;</span>
        <span class="s2">&quot;training runs. Note that either train-iters or &quot;</span>
        <span class="s2">&quot;train-samples should be provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--train-samples&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Total number of samples to train over all &quot;</span>
        <span class="s2">&quot;training runs. Note that either train-iters or &quot;</span>
        <span class="s2">&quot;train-samples should be provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--log-interval&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Report loss and timing interval.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--exit-interval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Exit the program after the iteration is divisible &quot;</span> <span class="s2">&quot;by this value.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--exit-duration-in-mins&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Exit the program after this many minutes.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tensorboard-dir&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Write TensorBoard logs to this directory.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-masked-softmax-fusion&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Disable fusion of query_key_value scaling, &quot;</span> <span class="s2">&quot;masking, and softmax.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;masked_softmax_fusion&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-bias-gelu-fusion&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Disable bias and gelu fusion.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;bias_gelu_fusion&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-bias-dropout-fusion&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Disable bias and dropout fusion.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;bias_dropout_fusion&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--optimizer&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="s2">&quot;sgd&quot;</span><span class="p">,</span> <span class="s2">&quot;lamb&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Optimizer function&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--dataloader-type&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;single&quot;</span><span class="p">,</span> <span class="s2">&quot;cyclic&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Single pass vs multiple pass data loader&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_initialization_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;initialization&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--seed&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Random seed used for python, numpy, &quot;</span> <span class="s2">&quot;pytorch, and cuda.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--init-method-std&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Standard deviation of the zero mean normal &quot;</span>
        <span class="s2">&quot;distribution used for weight initialization.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--init-method-xavier-uniform&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable Xavier uniform parameter initialization&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_learning_rate_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Initial learning rate. Depending on decay style &quot;</span>
        <span class="s2">&quot;and initial warmup, the learing rate at each &quot;</span>
        <span class="s2">&quot;iteration would be different.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-decay-style&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Learning rate decay function.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-decay-iters&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of iterations to decay learning rate over,&quot;</span>
        <span class="s2">&quot; If None defaults to `--train-iters`&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-decay-samples&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of samples to decay learning rate over,&quot;</span>
        <span class="s2">&quot; If None defaults to `--train-samples`&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-warmup-fraction&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;fraction of lr-warmup-(iters/samples) to use &quot;</span> <span class="s2">&quot;for warmup (as a float)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-warmup-iters&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of iterations to linearly warmup &quot;</span> <span class="s2">&quot;learning rate over.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-warmup-samples&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;number of samples to linearly warmup &quot;</span> <span class="s2">&quot;learning rate over.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--warmup&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Old lr warmup argument, do not use. Use one of the&quot;</span>
        <span class="s2">&quot;--lr-warmup-* arguments above&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--min-lr&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Minumum value for learning rate. The scheduler&quot;</span>
        <span class="s2">&quot;clip values below this threshold.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--override-lr-scheduler&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Reset the values of the scheduler (learning rate,&quot;</span>
        <span class="s2">&quot;warmup iterations, minimum learning rate, maximum &quot;</span>
        <span class="s2">&quot;number of iterations, and decay style from input &quot;</span>
        <span class="s2">&quot;arguments and ignore values from checkpoints. Note&quot;</span>
        <span class="s2">&quot;that all the above values will be reset.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--use-checkpoint-lr-scheduler&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use checkpoint to set the values of the scheduler &quot;</span>
        <span class="s2">&quot;(learning rate, warmup iterations, minimum learning &quot;</span>
        <span class="s2">&quot;rate, maximum number of iterations, and decay style &quot;</span>
        <span class="s2">&quot;from checkpoint and ignore input arguments.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_checkpointing_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;checkpointing&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--save&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Output directory to save checkpoints to.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--save-interval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of iterations between checkpoint saves.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-save-optim&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Do not save current optimizer.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-save-rng&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Do not save current rng state.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--load&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Directory containing a model checkpoint.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-load-optim&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Do not load optimizer when loading checkpoint.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-load-rng&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Do not load rng state when loading checkpoint.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--finetune&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Load model for finetuning. Do not load optimizer &quot;</span>
        <span class="s2">&quot;or rng state from checkpoint and set iteration to 0. &quot;</span>
        <span class="s2">&quot;Assumed when loading a release checkpoint.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_mixed_precision_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;mixed precision&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--fp16&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run model in fp16 mode.&quot;</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--bf16&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run model in bfloat16 mode.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--loss-scale&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Static loss scaling, positive power of 2 &quot;</span>
        <span class="s2">&quot;values can improve fp16 convergence. If None, dynamic&quot;</span>
        <span class="s2">&quot;loss scaling is used.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--initial-loss-scale&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Initial loss-scale for dynamic loss scaling.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--min-loss-scale&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Minimum loss scale for dynamic loss scale.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--loss-scale-window&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Window over which to raise/lower dynamic scale.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--hysteresis&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;hysteresis for dynamic loss scaling&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--fp32-residual-connection&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Move residual connections to fp32.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-query-key-layer-scaling&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Do not scale Q * K^T by 1 / layer-number.&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;apply_query_key_layer_scaling&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--attention-softmax-in-fp32&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run attention masking and softmax in fp32. &quot;</span>
        <span class="s2">&quot;This flag is ignored unless &quot;</span>
        <span class="s2">&quot;--no-query-key-layer-scaling is specified.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--accumulate-allreduce-grads-in-fp32&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Gradient accumulation and all-reduce in fp32.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--fp16-lm-cross-entropy&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Move the cross entropy unreduced loss calculation&quot;</span> <span class="s2">&quot;for lm head to fp16.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_distributed_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;distributed&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tensor-model-parallel-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Degree of tensor model parallelism.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--pipeline-model-parallel-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Degree of pipeline model parallelism.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--model-parallel-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Old model parallel argument, do not use. Use &quot;</span>
        <span class="s2">&quot;--tensor-model-parallel-size instead.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-layers-per-virtual-pipeline-stage&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of layers per virtual pipeline stage&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--distributed-backend&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="s2">&quot;gloo&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Which backend to use for distributed training.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--DDP-impl&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;which DistributedDataParallel implementation &quot;</span> <span class="s2">&quot;to use.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--use-contiguous-buffers-in-ddp&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, use contiguous buffer in DDP. Note that &quot;</span>
        <span class="s2">&quot;this option only works woth local DDP.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-scatter-gather-tensors-in-pipeline&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use scatter/gather to optimize communication of tensors in pipeline&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;scatter_gather_tensors_in_pipeline&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--local_rank&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;local rank passed from distributed launcher.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lazy-mpu-init&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set to True, initialize_megatron() &quot;</span>
        <span class="s2">&quot;skips DDP initialization and returns function to &quot;</span>
        <span class="s2">&quot;complete it instead.Also turns on &quot;</span>
        <span class="s2">&quot;--use-cpu-initialization flag. This is for &quot;</span>
        <span class="s2">&quot;external DDP manager.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--use-cpu-initialization&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If set, affine parallel weights &quot;</span> <span class="s2">&quot;initialization uses CPU&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_validation_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--eval-iters&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of iterations to run for evaluation&quot;</span> <span class="s2">&quot;validation/test for.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--eval-interval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Interval between running evaluation on &quot;</span> <span class="s2">&quot;validation set.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_data_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;data and dataloader&quot;</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--segment-length&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Length of signal patch.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--data-path&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the training dataset. Accepted format:&quot;</span>
        <span class="s2">&quot;1) a single data path, 2) multiple datasets in the&quot;</span>
        <span class="s2">&quot;form: dataset1-weight dataset1-path dataset2-weight &quot;</span>
        <span class="s2">&quot;dataset2-path ...&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--split&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;969, 30, 1&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Comma-separated list of proportions for training,&quot;</span>
        <span class="s2">&quot; validation, and test split. For example the split &quot;</span>
        <span class="s2">&quot;`90,5,5` will use 90</span><span class="si">%%</span><span class="s2"> of data for training, 5</span><span class="si">%%</span><span class="s2"> for &quot;</span>
        <span class="s2">&quot;validation and 5</span><span class="si">%%</span><span class="s2"> for test.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># group.add_argument(&#39;--vocab-file&#39;, type=str, default=None,</span>
    <span class="c1">#                    help=&#39;Path to the vocab file.&#39;)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--merge-file&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the BPE merge file.&quot;</span>
    <span class="p">)</span>
    <span class="c1"># group.add_argument(&#39;--vocab-extra-ids&#39;, type=int, default=0,</span>
    <span class="c1">#                    help=&#39;Number of additional vocabulary tokens. &#39;</span>
    <span class="c1">#                         &#39;They are used for span masking in the T5 model&#39;)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--seq-length&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum sequence length to process.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--dets&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;H1&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;detections that are used to generate data.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--encoder-seq-length&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum encoder sequence length to process.&quot;</span>
        <span class="s2">&quot;This should be exclusive of --seq-length&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--decoder-seq-length&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum decoder sequence length to process.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--retriever-seq-length&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum sequence length for the biencoder model &quot;</span> <span class="s2">&quot; for retriever&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--sample-rate&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;sample rate for training data. Supposed to be 0 &quot;</span> <span class="s2">&quot; &lt; sample_rate &lt; 1&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--mask-prob&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Probability of replacing a token with mask.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># group.add_argument(&#39;--short-seq-prob&#39;, type=float, default=0.1,</span>
    <span class="c1">#                    help=&#39;Probability of producing a short sequence.&#39;)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--mmap-warmup&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Warm up mmap files.&quot;</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-workers&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Dataloader number of workers.&quot;</span>
    <span class="p">)</span>
    <span class="c1"># group.add_argument(&#39;--tokenizer-type&#39;, type=str,</span>
    <span class="c1">#                    default=None,</span>
    <span class="c1">#                    choices=[&#39;BertWordPieceLowerCase&#39;,</span>
    <span class="c1">#                             &#39;BertWordPieceCase&#39;,</span>
    <span class="c1">#                             &#39;GPT2BPETokenizer&#39;],</span>
    <span class="c1">#                    help=&#39;What type of tokenizer to use.&#39;)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--data-impl&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;infer&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lazy&quot;</span><span class="p">,</span> <span class="s2">&quot;cached&quot;</span><span class="p">,</span> <span class="s2">&quot;mmap&quot;</span><span class="p">,</span> <span class="s2">&quot;infer&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Implementation of indexed datasets.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--reset-position-ids&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Reset posistion ids after end-of-document token.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--reset-attention-mask&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Reset self attention maske after &quot;</span> <span class="s2">&quot;end-of-document token.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--eod-mask-loss&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Mask loss for the end of document tokens.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_autoresume_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;autoresume&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--adlr-autoresume&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Enable autoresume on adlr cluster.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--adlr-autoresume-interval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Intervals over which check for autoresume&quot;</span> <span class="s2">&quot;termination signal&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_biencoder_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;biencoder&quot;</span><span class="p">)</span>

    <span class="c1"># network size</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--ict-head-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Size of block embeddings to be used in ICT and &quot;</span>
        <span class="s2">&quot;REALM (paper default: 128)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--biencoder-projection-dim&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Size of projection head used in biencoder (paper&quot;</span> <span class="s2">&quot; default: 128)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--biencoder-shared-query-context-model&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to share the parameters of the query &quot;</span>
        <span class="s2">&quot;and context models or not&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># data</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--titles-data-path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to titles dataset used for ICT&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--query-in-block-prob&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Probability of keeping query in block for &quot;</span> <span class="s2">&quot;ICT dataset&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--use-one-sent-docs&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to use one sentence documents in ICT&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--evidence-data-path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to Wikipedia Evidence frm DPR paper&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># training</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--retriever-report-topk-accuracies&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Which top-k accuracies to report &quot;</span> <span class="s2">&quot;(e.g. &#39;1 5 20&#39;)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--retriever-score-scaling&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to scale retriever scores by inverse &quot;</span>
        <span class="s2">&quot;square root of hidden size&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># faiss index</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--block-data-path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Where to save/load BlockData to/from&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--embedding-path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Where to save/load Open-Retrieval Embedding&quot;</span> <span class="s2">&quot; data to/from&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># indexer</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--indexer-batch-size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How large of batches to use when doing indexing &quot;</span> <span class="s2">&quot;jobs&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--indexer-log-interval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;After how many batches should the indexer &quot;</span> <span class="s2">&quot;report progress&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span>


<span class="k">def</span> <span class="nf">_add_vit_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;vit&quot;</span><span class="p">)</span>

    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-classes&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;num of classes in vision classificaiton task&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--img-dim&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Image size for vision classification task&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-channels&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of channels in input image data&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--patch-dim&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;patch dimension used in vit&quot;</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Yue Zhou, Tianyu Zhao.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>